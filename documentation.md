Core Model Information:
Developer: Microsoft Research
Size: 2.7 billion parameters
Training Data: 1.4 trillion tokens
Notable Feature: Performs like models 25x larger

Benchmark Performance:
    HumanEval: State-of-the-art performance in Python code generation
    MBPP: Excellent coding capabilities

Outperformed larger models including:
    Llama-2-70B
    Mistral and Llama-2 (7B and 13B versions)

Specialized Capabilities:
    Telecommunications domain expertise
    Radiology applications
    Multi-modal capabilities (text + visual)
    Strong noise pattern handling


Integration Details:
    Available through Azure AI Studio
    Suitable for research and development
    Good for mechanistic interpretability
    Supports fine-tuning